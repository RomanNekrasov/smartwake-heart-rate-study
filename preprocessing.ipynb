{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "id": "NFhMALw7OQY4",
    "outputId": "0abc9936-499f-499c-ca13-6379292b5b22"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "from format_the_data import format_mi_band_data\n",
    "from feature_engineering import get_wake_up_info_miband, get_wake_up_info_applewatch, get_heartrate_data_for_interval, calculate_test_statistics_heartrate\n",
    "from load_the_data import process_fitness_data\n",
    "import json\n",
    "from pprint import pprint\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set os dir to data, same director but in folder data\n",
    "os.chdir('data')\n",
    "person1 = pd.read_csv('20231030_8210796956_MiFitness_hlth_center_fitness_data.csv')\n",
    "person2 = pd.read_csv('20231030_8211531339_MiFitness_hlth_center_fitness_data.csv')\n",
    "person3 = pd.read_csv('20231031_8210564343_MiFitness_hlth_center_fitness_data.csv')\n",
    "person4 = pd.read_csv('20231110_8210586841_MiFitness_hlth_center_fitness_data.csv')\n",
    "\n",
    "person1['Person ID'] = 1\n",
    "person2['Person ID'] = 2\n",
    "person3['Person ID'] = 3\n",
    "person4['Person ID'] = 4\n",
    "\n",
    "apple_sleep_data = pd.read_csv('sleep_apple.csv')\n",
    "apple_heart_rate_data = pd.read_csv('heart_rate_apple.csv')\n",
    "\n",
    "master_frame = pd.concat([person1, person2, person3, person4], ignore_index=True)\n",
    "\n",
    "behaviour_tracking_data = pd.read_csv('Behavioural data app.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = behaviour_tracking_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_keys = ['pai',\n",
    "               'valid_stand', \n",
    "               'calories',\n",
    "               'steps',\n",
    "               'heart_rate',\n",
    "               'intensity',\n",
    "               'dynamic',\n",
    "               'single_heart_rate',\n",
    "               'single_spo2',\n",
    "               'training_load',\n",
    "               'single_stress',\n",
    "               'stress',\n",
    "               'watch_night_sleep',\n",
    "               'resting_heart_rate',\n",
    "               'watch_daytime_sleep',\n",
    "               'weight']\n",
    "key_dataframes = format_mi_band_data(unique_keys, master_frame)\n",
    "\n",
    "\n",
    "# separate dataframes:\n",
    "pai_df = key_dataframes['pai']\n",
    "valid_stand_df = key_dataframes['valid_stand']\n",
    "calories_df = key_dataframes['calories']\n",
    "steps_df = key_dataframes['steps']\n",
    "heart_rate_df = key_dataframes['heart_rate']\n",
    "intensity_df = key_dataframes['intensity']\n",
    "dynamic_df = key_dataframes['dynamic']\n",
    "single_heart_rate_df = key_dataframes['single_heart_rate']\n",
    "single_spo2_df = key_dataframes['single_spo2']\n",
    "training_load_df = key_dataframes['training_load']\n",
    "single_stress_df = key_dataframes['single_stress']\n",
    "stress_df = key_dataframes['stress']\n",
    "watch_night_sleep_df = key_dataframes['watch_night_sleep']\n",
    "resting_heart_rate_df = key_dataframes['resting_heart_rate']\n",
    "watch_daytime_sleep_df = key_dataframes['watch_daytime_sleep']\n",
    "weight_df = key_dataframes['weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Y0nf2tFlw1p"
   },
   "source": [
    "# Intuition\n",
    "\n",
    "I think we need to include control variables such as the number of hours sleep and the quality of sleep as this significantly influences your mental state after awaking.\n",
    "\n",
    "I guess we can check whether someone has slept after their alarm right?\n",
    "\n",
    "We must include variable for smart alarm or not. Can we find this in the settings from the mi band?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to add features from our watch data to the behavioural data.\n",
    "\n",
    "Features for our analysis:\n",
    "- Average of the first 20 minutes after waking\n",
    "- Whether the smart alarm actually woke us up in light sleep (not in deep or REM)\n",
    "\n",
    "Hence we need:\n",
    "- Waking time\n",
    "- Heartrate data\n",
    "- State when awaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person ID\n",
       "1    28\n",
       "2    27\n",
       "5    26\n",
       "4    23\n",
       "3    15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_df['Person ID'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate sleepdata and add to aggregated_df (with behavioural data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df['Date'] = pd.to_datetime(aggregated_df['Date created']).dt.date\n",
    "\n",
    "# for apple watch\n",
    "aggregated_df_person_5 = aggregated_df[aggregated_df['Person ID'] == 5]\n",
    "aggregated_df_person_5 = get_wake_up_info_applewatch(apple_sleep_data, aggregated_df_person_5)\n",
    "\n",
    "# for mi band\n",
    "aggregated_df_rest = aggregated_df[aggregated_df['Person ID'] != 5]\n",
    "aggregated_df_rest = get_wake_up_info_miband(watch_night_sleep_df, aggregated_df_rest)\n",
    "\n",
    "# aggregate\n",
    "aggregated_df = pd.concat([aggregated_df_person_5, aggregated_df_rest], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "print(len(aggregated_df))\n",
    "# filter out the rows where the time_of_awakening is NaN\n",
    "aggregated_df = aggregated_df[~aggregated_df['time_of_awakening'].isna()].reset_index(drop=True)\n",
    "print(len(aggregated_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here 8 observations could not be linked due to missing sleepdata caused by Xiaomi export fail\n",
    "\n",
    "## Lets aggregate the heart rate for the devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the relevant columns of heart rate data\n",
    "heart_rate_df = heart_rate_df[['Person ID', 'Time', 'bpm']]\n",
    "\n",
    "# Prepare apple_heart_rate_data for merging\n",
    "apple_data_prepared = apple_heart_rate_data[['creationDate', 'value']].copy()\n",
    "apple_data_prepared.rename(columns={'value': 'bpm'}, inplace=True)\n",
    "apple_data_prepared['Person ID'] = 5\n",
    "\n",
    "# Convert 'creationDate' to Unix epoch time (seconds since epoch)\n",
    "apple_data_prepared['creationDate'] = pd.to_datetime(apple_data_prepared['creationDate'])\n",
    "apple_data_prepared['Time'] = apple_data_prepared['creationDate'].astype('int64') // 10**9\n",
    "\n",
    "# Drop the original 'creationDate' column\n",
    "apple_data_prepared.drop('creationDate', axis=1, inplace=True)\n",
    "\n",
    "# Use concat instead of append\n",
    "heart_rate_df = pd.concat([heart_rate_df, apple_data_prepared], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next we get the insights and add to aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = 60  # Assuming a 60 minute interval\n",
    "\n",
    "# Add new columns for the statistics in behaviour_tracking_data\n",
    "aggregated_df['Number of Measurements'] = pd.NA\n",
    "aggregated_df['Average Heart Rate'] = pd.NA\n",
    "aggregated_df['Average Lowest Three obs'] = pd.NA\n",
    "aggregated_df['Average First Ten min'] = pd.NA\n",
    "aggregated_df['Average First Thirty min'] = pd.NA\n",
    "\n",
    "for index, row in aggregated_df.iterrows():\n",
    "    # Get heart rate data for the interval\n",
    "    heart_rate_data = get_heartrate_data_for_interval(heart_rate_df, row['Person ID'], row['Date'], row['time_of_awakening'], time_interval)\n",
    "    \n",
    "    # Calculate the test statistics\n",
    "    num_measurements, avg_hr, avg_lowest_three, avg_first_ten, avg_first_thirty = calculate_test_statistics_heartrate(heart_rate_data)\n",
    "\n",
    "    # Update the aggregated_df DataFrame with the new statistics\n",
    "    aggregated_df.at[index, 'Number of Measurements'] = num_measurements\n",
    "    aggregated_df.at[index, 'Average Heart Rate'] = avg_hr\n",
    "    aggregated_df.at[index, 'Average Lowest Three obs'] = avg_lowest_three\n",
    "    aggregated_df.at[index, 'Average First Ten min'] = avg_first_ten\n",
    "    aggregated_df.at[index, 'Average First Thirty min'] = avg_first_thirty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning out outliers due to sport activity or too little measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outliers removed for each 'Person ID' (above 100):\n",
      "Person ID\n",
      "5    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count outliers below 6 and above 100 for each 'Person ID'\n",
    "outliers_below_6 = aggregated_df[aggregated_df['Number of Measurements'] < 6].groupby('Person ID').size()\n",
    "outliers_above_100 = aggregated_df[aggregated_df['Number of Measurements'] > 100].groupby('Person ID').size()\n",
    "\n",
    "# Filter out the outliers\n",
    "filtered_df = aggregated_df[(aggregated_df['Number of Measurements'] >= 6) & (aggregated_df['Number of Measurements'] <= 100)]\n",
    "\n",
    "# Check and report the counts of outliers removed\n",
    "if not outliers_below_6.empty or not outliers_above_100.empty:\n",
    "    if not outliers_below_6.empty:\n",
    "        print(\"Outliers removed for each 'Person ID' (below 6):\")\n",
    "        print(outliers_below_6)\n",
    "    if not outliers_above_100.empty:\n",
    "        print(\"\\nOutliers removed for each 'Person ID' (above 100):\")\n",
    "        print(outliers_above_100)\n",
    "else:\n",
    "    print(\"No outliers in your data!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all False values with 0 and True values with 1 in aggregated_df\n",
    "aggregated_df = aggregated_df.replace(False, 0)\n",
    "aggregated_df = aggregated_df.replace(True, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the aggregated_df DataFrame to a csv file\n",
    "aggregated_df.to_csv('aggregated_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
